{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ANNProjectKeras.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7ThZvesJO2t1","colab_type":"text"},"source":["## **PROJECT ARTIFICIAL NEURAL NETWORK (CONVOLUTIONAL NEURAL NETWORK)**\n","\n","Name : Satria Wiro Agung\n","\n","NIM : 2101662133\n","\n","Class : LB08\n","\n","\n","## Convolutional Neural Network with Fashion.Mnist dataset\n","\n","Training Data : 48000 images\n","\n","Validation Data : 12000 images\n","\n","Testing Data : 10000 images\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"G2qN5Y3sO1Q_","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard\n","from keras.datasets import fashion_mnist\n","from keras.utils import np_utils\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from keras.optimizers import SGD"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M6vKcE17nWrZ","colab_type":"text"},"source":["## **LOAD DATA AND PREPROCESSING**"]},{"cell_type":"code","metadata":{"id":"E1d9hOviL_ZF","colab_type":"code","colab":{}},"source":["((trainDatas, trainLabels), (testDatas, testLabels)) = fashion_mnist.load_data()\n","trainDatas = trainDatas.astype(\"float32\") / 255.0\n","testDatas = testDatas.astype(\"float32\") / 255.0\n","\n","# One-hot Encoding untuk trainLabels dan testLabels\n","trainLabels = np_utils.to_categorical(trainLabels, 10)\n","testLabels = np_utils.to_categorical(testLabels, 10)\n","\n","# Memisahkan training dataset menjadi trainData dan validateDatas\n","\n","trainDatas, validateDatas, trainLabels, validateLabels = train_test_split(\n","    trainDatas, trainLabels, test_size = 0.2, random_state = 42\n",")\n","\n","\n","# Reshape Data\n","img_rows = 28\n","img_cols = 28\n","batch_size = 500\n","img_shape = (img_rows, img_cols, 1)\n","\n","trainDatas = trainDatas.reshape(trainDatas.shape[0], *img_shape)\n","testDatas = testDatas.reshape(testDatas.shape[0], *img_shape)\n","validateDatas = validateDatas.reshape(validateDatas.shape[0], *img_shape)\n","print(trainDatas.shape[3])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V6EnwV2vSyva","colab_type":"text"},"source":["Data dan label untuk training dan testing diimport dari dataset Fashion_Mnist. Setiap data/image berukuran 28x28 pixels dengan nilai setiap pixel 0 - 255. Untuk dapat digunakan dalam komputasi dan juga untuk mengurangi kompleksitas kalkulasi maka value dari setiap pixel pada train data dan test data harus diubah ke float dan dibagi 255 untuk mengubah nilai pixel diantara 0 - 1. \n","\n","Kemudian Label akan diubah menjadi One Hot Encoding. Contoh untuk label \"T-Shirt\" maka One Hot Encodingnya = [1,0,0,0,0,0,0,0,0,0], untuk label \"Trouser\" maka = [0,1,0,0,0,0,0,0,0,0].\n","One Hot Encoding digunakan untuk merepresentasikan data yang berkategori.\n","\n","Train Data kemudian akan dibagi menjadi 2 yaitu Train Data(80%) dan Validation Data(20%). Validation bertujuan untuk mencegah overfitting.\n","\n","Train Data, Test Data dan Validation Data akan direshape menjadi 28 x 28 greyscale.\n"]},{"cell_type":"markdown","metadata":{"id":"kYrJYooYngSD","colab_type":"text"},"source":["## **CREATE CNN MODEL**"]},{"cell_type":"code","metadata":{"id":"i7QQt5IAMBDc","colab_type":"code","outputId":"aef753c7-f3de-4165-f316-b72bfeee70cb","executionInfo":{"status":"ok","timestamp":1572086776484,"user_tz":-420,"elapsed":3747,"user":{"displayName":"Satria Wiro Agung","photoUrl":"","userId":"00696212505222063717"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# CNN MODEL\n","name = 'CNN_1Layer'\n","cnn_model_1Layer = Sequential([\n","    Conv2D(32, kernel_size = 3, activation = 'relu',input_shape = img_shape, name = 'Conv2D-1'),\n","    MaxPooling2D(pool_size = 2, name='MaxPool'),\n","    Dropout(0.2, name='Dropout'),\n","    Flatten(name='Flatten'),\n","    \n","    Dense(32, activation = 'relu', name='Dense'),\n","    Dense(10, activation = 'softmax', name='Output')\n","],name = name)\n","\n","name = 'CNN_2Layer'\n","cnn_model_2Layer = Sequential([\n","    Conv2D(32, kernel_size = 3, activation = 'relu', input_shape = img_shape, name='Conv2D-1'),\n","    MaxPooling2D(pool_size = 2, name = 'MaxPool'),\n","    Dropout(0.2, name='Dropout-1'),\n","    \n","    Conv2D(64,kernel_size = 3, activation = 'relu', name='Conv2D-2'),\n","    Dropout(0.25, name='Dropout-2'),\n","    Flatten(name='Flatten'),\n","    \n","    Dense(64, activation = 'relu', name='Dense'),\n","    Dense(10, activation = 'softmax', name='Output')\n","],name = name)\n","\n","name='CNN_3Layer'\n","cnn_model_3Layer = Sequential([\n","    Conv2D(32, kernel_size=3, activation='relu', input_shape=img_shape, kernel_initializer='he_normal', name='Conv2D-1'),\n","    MaxPooling2D(pool_size=2, name='MaxPool'),\n","    Dropout(0.25, name='Dropout-1'),\n","    \n","    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n","    Dropout(0.25, name='Dropout-2'),\n","    \n","    Conv2D(128, kernel_size=3, activation='relu', name='Conv2D-3'),\n","    Dropout(0.4, name='Dropout-3'),\n","    Flatten(name='flatten'),\n","    \n","    Dense(128, activation='relu', name='Dense'),\n","    Dropout(0.4, name='Dropout'),\n","    Dense(10, activation='softmax', name='Output')\n","], name=name)\n","\n","cnn_models = [cnn_model_1Layer,cnn_model_2Layer,cnn_model_3Layer]\n","for model in cnn_models:\n","  model.summary();"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"CNN_1Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Dropout (Dropout)            (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Flatten (Flatten)            (None, 5408)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 32)                173088    \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                330       \n","=================================================================\n","Total params: 173,738\n","Trainable params: 173,738\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"CNN_2Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n","_________________________________________________________________\n","Flatten (Flatten)            (None, 7744)              0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 64)                495680    \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                650       \n","=================================================================\n","Total params: 515,146\n","Trainable params: 515,146\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"CNN_3Layer\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Conv2D-1 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","MaxPool (MaxPooling2D)       (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Dropout-1 (Dropout)          (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","Conv2D-2 (Conv2D)            (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","Dropout-2 (Dropout)          (None, 11, 11, 64)        0         \n","_________________________________________________________________\n","Conv2D-3 (Conv2D)            (None, 9, 9, 128)         73856     \n","_________________________________________________________________\n","Dropout-3 (Dropout)          (None, 9, 9, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 10368)             0         \n","_________________________________________________________________\n","Dense (Dense)                (None, 128)               1327232   \n","_________________________________________________________________\n","Dropout (Dropout)            (None, 128)               0         \n","_________________________________________________________________\n","Output (Dense)               (None, 10)                1290      \n","=================================================================\n","Total params: 1,421,194\n","Trainable params: 1,421,194\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FrWZfZbanIQC","colab_type":"text"},"source":["3 Model CNN yang akan digunakan : \n","\n","\n","**Model 1 : 1 Convolutional Layer**\n","\n","Convolution Layer dengan 32 filters/nodes menggunakan activition function relu. Setelah itu akan MaxPooling(Size = 2) untuk mengekstrak pixel/feature yang paling dominan dari hasil convolution layer. Kemudian Dropout(20%) akan dilakukan untuk mencegah/mengurangi overfitting. Terakhir hasil dari proses diatas akan diflatten (diubah menjadi sebuah vektor).\n","\n","\n","Dense Layer dengan 32 node , Activition Function : ReLu\n","\n","\n","Dense Layer dengan 10 node(menandakan 10 label dari data Fashion.Mnist). Activition Function : Softmax.\n","\n","\n","**Model 2 : 2 Convolutional Layer**\n","\n","Convolutional Layer ke 1  : 32 filter, kernel size = 3, Activition : Relu,\n","Kemudian Max Pooling dengan size = 2, Dropout = 25 persen.\n","\n","Convolutional Layer ke 2  : 64 filter, kernel size = 3, Activition : Relu,\n","Kemudian Dropout = 25 persen dan hasil di Flatten.\n","\n","Dense Layer 1 : 64 Node, Activition = Relu.\n","\n","Dense Layer 2 (Output Layer)  : 10 Node , Activition = Softmax\n","\n","\n","**Model 3 : 3 Convolutional Layer**\n","\n","Convolutional Layer ke 1  : 32 filter, kernel size = 3, Activition : Relu,\n","Kemudian Max Pooling dengan size = 2, Dropout = 25 persen.\n","\n","Convolutional Layer ke 2  : 64 filter, kernel size = 3, Activition : Relu,\n","Kemudian Dropout = 25 persen.\n","\n","Convolutional Layer ke 3  : 128 filter, kernel size = 3, Activition : Relu,\n","Kemudian Dropout = 25 persen dan hasil di Flatten.\n","\n","Dense Layer 1 : 64 Node, Activition = Relu. Kemudian Dropout 40 persen.\n","\n","Dense Layer 2 (Output Layer)  : 10 Node , Activition = Softmax\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VcC6QruVnmgJ","colab_type":"text"},"source":["## **TRAIN CNN MODEL**\n","\n","Loss function yang digunakan adalah Categorical Crossentropy.\n","Optimizer yang digunakan adalah Adam.\n","Jumlah Epoch : 50\n","Batch Size : 500"]},{"cell_type":"code","metadata":{"id":"LoPHudXaQSPU","colab_type":"code","outputId":"24adf540-5de1-4156-8532-8b3c773ad303","executionInfo":{"status":"ok","timestamp":1572094929358,"user_tz":-420,"elapsed":4372526,"user":{"displayName":"Satria Wiro Agung","photoUrl":"","userId":"00696212505222063717"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Train Model dan Hasil disimpan dalam dictionary\n","result_dict = {}\n","\n","for model in cnn_models:\n","    model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer=Adam(),\n","        metrics=['accuracy']\n","    )\n","    \n","    result = model.fit(\n","        trainDatas, trainLabels,\n","        batch_size=batch_size,\n","        epochs=50, verbose=1,\n","        validation_data=(validateDatas, validateLabels)\n","    )\n","    \n","    result_dict[model.name] = result"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 48000 samples, validate on 12000 samples\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","48000/48000 [==============================] - 22s 463us/step - loss: 0.7615 - acc: 0.7526 - val_loss: 0.4775 - val_acc: 0.8390\n","Epoch 2/50\n","48000/48000 [==============================] - 20s 424us/step - loss: 0.4385 - acc: 0.8471 - val_loss: 0.3952 - val_acc: 0.8627\n","Epoch 3/50\n","48000/48000 [==============================] - 20s 422us/step - loss: 0.3883 - acc: 0.8639 - val_loss: 0.3618 - val_acc: 0.8754\n","Epoch 4/50\n","48000/48000 [==============================] - 20s 415us/step - loss: 0.3603 - acc: 0.8733 - val_loss: 0.3474 - val_acc: 0.8782\n","Epoch 5/50\n","48000/48000 [==============================] - 20s 420us/step - loss: 0.3375 - acc: 0.8820 - val_loss: 0.3257 - val_acc: 0.8861\n","Epoch 6/50\n","48000/48000 [==============================] - 20s 418us/step - loss: 0.3209 - acc: 0.8873 - val_loss: 0.3205 - val_acc: 0.8858\n","Epoch 7/50\n","48000/48000 [==============================] - 20s 418us/step - loss: 0.3071 - acc: 0.8920 - val_loss: 0.3080 - val_acc: 0.8907\n","Epoch 8/50\n","48000/48000 [==============================] - 20s 421us/step - loss: 0.2968 - acc: 0.8960 - val_loss: 0.3018 - val_acc: 0.8941\n","Epoch 9/50\n","48000/48000 [==============================] - 20s 418us/step - loss: 0.2862 - acc: 0.8984 - val_loss: 0.2919 - val_acc: 0.8967\n","Epoch 10/50\n","48000/48000 [==============================] - 20s 412us/step - loss: 0.2771 - acc: 0.9020 - val_loss: 0.2914 - val_acc: 0.8957\n","Epoch 11/50\n","48000/48000 [==============================] - 20s 420us/step - loss: 0.2691 - acc: 0.9040 - val_loss: 0.2865 - val_acc: 0.8971\n","Epoch 12/50\n","48000/48000 [==============================] - 20s 426us/step - loss: 0.2630 - acc: 0.9080 - val_loss: 0.2838 - val_acc: 0.8978\n","Epoch 13/50\n","48000/48000 [==============================] - 22s 451us/step - loss: 0.2564 - acc: 0.9085 - val_loss: 0.2791 - val_acc: 0.8991\n","Epoch 14/50\n","48000/48000 [==============================] - 21s 431us/step - loss: 0.2503 - acc: 0.9114 - val_loss: 0.2739 - val_acc: 0.9013\n","Epoch 15/50\n","48000/48000 [==============================] - 21s 436us/step - loss: 0.2420 - acc: 0.9133 - val_loss: 0.2684 - val_acc: 0.9034\n","Epoch 16/50\n","48000/48000 [==============================] - 21s 434us/step - loss: 0.2406 - acc: 0.9131 - val_loss: 0.2654 - val_acc: 0.9057\n","Epoch 17/50\n","48000/48000 [==============================] - 21s 435us/step - loss: 0.2330 - acc: 0.9165 - val_loss: 0.2663 - val_acc: 0.9052\n","Epoch 18/50\n","48000/48000 [==============================] - 21s 437us/step - loss: 0.2315 - acc: 0.9159 - val_loss: 0.2594 - val_acc: 0.9052\n","Epoch 19/50\n","48000/48000 [==============================] - 21s 436us/step - loss: 0.2277 - acc: 0.9178 - val_loss: 0.2621 - val_acc: 0.9075\n","Epoch 20/50\n","48000/48000 [==============================] - 21s 441us/step - loss: 0.2192 - acc: 0.9212 - val_loss: 0.2553 - val_acc: 0.9082\n","Epoch 21/50\n","48000/48000 [==============================] - 21s 428us/step - loss: 0.2172 - acc: 0.9209 - val_loss: 0.2562 - val_acc: 0.9088\n","Epoch 22/50\n","48000/48000 [==============================] - 20s 423us/step - loss: 0.2150 - acc: 0.9239 - val_loss: 0.2561 - val_acc: 0.9093\n","Epoch 23/50\n","48000/48000 [==============================] - 20s 416us/step - loss: 0.2102 - acc: 0.9234 - val_loss: 0.2573 - val_acc: 0.9065\n","Epoch 24/50\n","48000/48000 [==============================] - 20s 416us/step - loss: 0.2049 - acc: 0.9266 - val_loss: 0.2551 - val_acc: 0.9085\n","Epoch 25/50\n","48000/48000 [==============================] - 20s 413us/step - loss: 0.2014 - acc: 0.9278 - val_loss: 0.2555 - val_acc: 0.9081\n","Epoch 26/50\n","48000/48000 [==============================] - 20s 417us/step - loss: 0.1998 - acc: 0.9274 - val_loss: 0.2551 - val_acc: 0.9082\n","Epoch 27/50\n","48000/48000 [==============================] - 20s 413us/step - loss: 0.1938 - acc: 0.9303 - val_loss: 0.2500 - val_acc: 0.9104\n","Epoch 28/50\n","48000/48000 [==============================] - 20s 413us/step - loss: 0.1969 - acc: 0.9291 - val_loss: 0.2539 - val_acc: 0.9106\n","Epoch 29/50\n","48000/48000 [==============================] - 20s 414us/step - loss: 0.1904 - acc: 0.9313 - val_loss: 0.2662 - val_acc: 0.9053\n","Epoch 30/50\n","48000/48000 [==============================] - 20s 420us/step - loss: 0.1848 - acc: 0.9331 - val_loss: 0.2477 - val_acc: 0.9117\n","Epoch 31/50\n","48000/48000 [==============================] - 20s 423us/step - loss: 0.1811 - acc: 0.9337 - val_loss: 0.2452 - val_acc: 0.9147\n","Epoch 32/50\n","48000/48000 [==============================] - 20s 417us/step - loss: 0.1791 - acc: 0.9353 - val_loss: 0.2478 - val_acc: 0.9142\n","Epoch 33/50\n","48000/48000 [==============================] - 20s 412us/step - loss: 0.1795 - acc: 0.9341 - val_loss: 0.2451 - val_acc: 0.9167\n","Epoch 34/50\n","48000/48000 [==============================] - 20s 412us/step - loss: 0.1731 - acc: 0.9379 - val_loss: 0.2496 - val_acc: 0.9142\n","Epoch 35/50\n","48000/48000 [==============================] - 20s 416us/step - loss: 0.1727 - acc: 0.9368 - val_loss: 0.2494 - val_acc: 0.9143\n","Epoch 36/50\n","48000/48000 [==============================] - 20s 415us/step - loss: 0.1698 - acc: 0.9361 - val_loss: 0.2525 - val_acc: 0.9128\n","Epoch 37/50\n","48000/48000 [==============================] - 20s 411us/step - loss: 0.1658 - acc: 0.9399 - val_loss: 0.2538 - val_acc: 0.9155\n","Epoch 38/50\n","48000/48000 [==============================] - 20s 415us/step - loss: 0.1628 - acc: 0.9411 - val_loss: 0.2549 - val_acc: 0.9129\n","Epoch 39/50\n","48000/48000 [==============================] - 20s 411us/step - loss: 0.1599 - acc: 0.9425 - val_loss: 0.2445 - val_acc: 0.9167\n","Epoch 40/50\n","48000/48000 [==============================] - 20s 412us/step - loss: 0.1580 - acc: 0.9424 - val_loss: 0.2493 - val_acc: 0.9168\n","Epoch 41/50\n","48000/48000 [==============================] - 20s 407us/step - loss: 0.1573 - acc: 0.9418 - val_loss: 0.2469 - val_acc: 0.9178\n","Epoch 42/50\n","48000/48000 [==============================] - 20s 408us/step - loss: 0.1546 - acc: 0.9434 - val_loss: 0.2425 - val_acc: 0.9172\n","Epoch 43/50\n","48000/48000 [==============================] - 20s 410us/step - loss: 0.1509 - acc: 0.9454 - val_loss: 0.2520 - val_acc: 0.9168\n","Epoch 44/50\n","48000/48000 [==============================] - 20s 419us/step - loss: 0.1481 - acc: 0.9461 - val_loss: 0.2474 - val_acc: 0.9158\n","Epoch 45/50\n","48000/48000 [==============================] - 20s 417us/step - loss: 0.1459 - acc: 0.9467 - val_loss: 0.2479 - val_acc: 0.9152\n","Epoch 46/50\n","48000/48000 [==============================] - 20s 427us/step - loss: 0.1446 - acc: 0.9463 - val_loss: 0.2560 - val_acc: 0.9149\n","Epoch 47/50\n","48000/48000 [==============================] - 21s 431us/step - loss: 0.1419 - acc: 0.9483 - val_loss: 0.2459 - val_acc: 0.9168\n","Epoch 48/50\n","48000/48000 [==============================] - 21s 442us/step - loss: 0.1393 - acc: 0.9501 - val_loss: 0.2518 - val_acc: 0.9159\n","Epoch 49/50\n","48000/48000 [==============================] - 20s 420us/step - loss: 0.1371 - acc: 0.9503 - val_loss: 0.2511 - val_acc: 0.9184\n","Epoch 50/50\n","48000/48000 [==============================] - 20s 413us/step - loss: 0.1359 - acc: 0.9511 - val_loss: 0.2504 - val_acc: 0.9165\n","Train on 48000 samples, validate on 12000 samples\n","Epoch 1/50\n","48000/48000 [==============================] - 45s 934us/step - loss: 0.7131 - acc: 0.7478 - val_loss: 0.4796 - val_acc: 0.8268\n","Epoch 2/50\n","48000/48000 [==============================] - 45s 942us/step - loss: 0.4346 - acc: 0.8451 - val_loss: 0.3785 - val_acc: 0.8661\n","Epoch 3/50\n","48000/48000 [==============================] - 45s 938us/step - loss: 0.3776 - acc: 0.8674 - val_loss: 0.3405 - val_acc: 0.8782\n","Epoch 4/50\n","48000/48000 [==============================] - 45s 937us/step - loss: 0.3415 - acc: 0.8783 - val_loss: 0.3274 - val_acc: 0.8783\n","Epoch 5/50\n","48000/48000 [==============================] - 46s 964us/step - loss: 0.3215 - acc: 0.8849 - val_loss: 0.2992 - val_acc: 0.8923\n","Epoch 6/50\n","48000/48000 [==============================] - 45s 943us/step - loss: 0.3058 - acc: 0.8899 - val_loss: 0.2870 - val_acc: 0.8986\n","Epoch 7/50\n","48000/48000 [==============================] - 47s 973us/step - loss: 0.2847 - acc: 0.8973 - val_loss: 0.2712 - val_acc: 0.9005\n","Epoch 8/50\n","48000/48000 [==============================] - 46s 963us/step - loss: 0.2740 - acc: 0.9023 - val_loss: 0.2682 - val_acc: 0.9020\n","Epoch 9/50\n","48000/48000 [==============================] - 45s 938us/step - loss: 0.2632 - acc: 0.9050 - val_loss: 0.2572 - val_acc: 0.9039\n","Epoch 10/50\n","48000/48000 [==============================] - 44s 918us/step - loss: 0.2514 - acc: 0.9099 - val_loss: 0.2576 - val_acc: 0.9044\n","Epoch 11/50\n","48000/48000 [==============================] - 44s 916us/step - loss: 0.2450 - acc: 0.9106 - val_loss: 0.2443 - val_acc: 0.9098\n","Epoch 12/50\n","48000/48000 [==============================] - 46s 948us/step - loss: 0.2331 - acc: 0.9160 - val_loss: 0.2390 - val_acc: 0.9130\n","Epoch 13/50\n","48000/48000 [==============================] - 45s 938us/step - loss: 0.2266 - acc: 0.9167 - val_loss: 0.2413 - val_acc: 0.9115\n","Epoch 14/50\n","48000/48000 [==============================] - 44s 927us/step - loss: 0.2186 - acc: 0.9200 - val_loss: 0.2403 - val_acc: 0.9089\n","Epoch 15/50\n","48000/48000 [==============================] - 44s 926us/step - loss: 0.2112 - acc: 0.9234 - val_loss: 0.2299 - val_acc: 0.9168\n","Epoch 16/50\n","48000/48000 [==============================] - 44s 922us/step - loss: 0.2041 - acc: 0.9264 - val_loss: 0.2383 - val_acc: 0.9127\n","Epoch 17/50\n","48000/48000 [==============================] - 45s 927us/step - loss: 0.1959 - acc: 0.9284 - val_loss: 0.2231 - val_acc: 0.9179\n","Epoch 18/50\n","48000/48000 [==============================] - 45s 929us/step - loss: 0.1913 - acc: 0.9302 - val_loss: 0.2186 - val_acc: 0.9205\n","Epoch 19/50\n","48000/48000 [==============================] - 45s 933us/step - loss: 0.1866 - acc: 0.9314 - val_loss: 0.2317 - val_acc: 0.9144\n","Epoch 20/50\n","48000/48000 [==============================] - 45s 942us/step - loss: 0.1833 - acc: 0.9330 - val_loss: 0.2218 - val_acc: 0.9199\n","Epoch 21/50\n","48000/48000 [==============================] - 46s 952us/step - loss: 0.1774 - acc: 0.9340 - val_loss: 0.2211 - val_acc: 0.9197\n","Epoch 22/50\n","48000/48000 [==============================] - 45s 929us/step - loss: 0.1710 - acc: 0.9368 - val_loss: 0.2103 - val_acc: 0.9237\n","Epoch 23/50\n","48000/48000 [==============================] - 44s 925us/step - loss: 0.1668 - acc: 0.9387 - val_loss: 0.2151 - val_acc: 0.9213\n","Epoch 24/50\n","48000/48000 [==============================] - 45s 941us/step - loss: 0.1600 - acc: 0.9396 - val_loss: 0.2271 - val_acc: 0.9171\n","Epoch 25/50\n","48000/48000 [==============================] - 44s 924us/step - loss: 0.1590 - acc: 0.9412 - val_loss: 0.2103 - val_acc: 0.9217\n","Epoch 26/50\n","48000/48000 [==============================] - 46s 956us/step - loss: 0.1508 - acc: 0.9443 - val_loss: 0.2071 - val_acc: 0.9244\n","Epoch 27/50\n","48000/48000 [==============================] - 45s 939us/step - loss: 0.1493 - acc: 0.9448 - val_loss: 0.2203 - val_acc: 0.9226\n","Epoch 28/50\n","48000/48000 [==============================] - 45s 928us/step - loss: 0.1464 - acc: 0.9461 - val_loss: 0.2110 - val_acc: 0.9219\n","Epoch 29/50\n","48000/48000 [==============================] - 45s 940us/step - loss: 0.1428 - acc: 0.9469 - val_loss: 0.2088 - val_acc: 0.9232\n","Epoch 30/50\n","48000/48000 [==============================] - 44s 923us/step - loss: 0.1368 - acc: 0.9488 - val_loss: 0.2086 - val_acc: 0.9238\n","Epoch 31/50\n","48000/48000 [==============================] - 45s 933us/step - loss: 0.1340 - acc: 0.9502 - val_loss: 0.2157 - val_acc: 0.9239\n","Epoch 32/50\n","48000/48000 [==============================] - 45s 936us/step - loss: 0.1276 - acc: 0.9523 - val_loss: 0.2104 - val_acc: 0.9245\n","Epoch 33/50\n","48000/48000 [==============================] - 46s 959us/step - loss: 0.1249 - acc: 0.9542 - val_loss: 0.2098 - val_acc: 0.9261\n","Epoch 34/50\n","48000/48000 [==============================] - 44s 916us/step - loss: 0.1242 - acc: 0.9537 - val_loss: 0.2035 - val_acc: 0.9283\n","Epoch 35/50\n","48000/48000 [==============================] - 44s 921us/step - loss: 0.1176 - acc: 0.9563 - val_loss: 0.2042 - val_acc: 0.9276\n","Epoch 36/50\n","48000/48000 [==============================] - 44s 914us/step - loss: 0.1168 - acc: 0.9568 - val_loss: 0.2104 - val_acc: 0.9255\n","Epoch 37/50\n","48000/48000 [==============================] - 44s 919us/step - loss: 0.1139 - acc: 0.9574 - val_loss: 0.2094 - val_acc: 0.9247\n","Epoch 38/50\n","48000/48000 [==============================] - 44s 926us/step - loss: 0.1075 - acc: 0.9600 - val_loss: 0.2136 - val_acc: 0.9274\n","Epoch 39/50\n","48000/48000 [==============================] - 45s 934us/step - loss: 0.1073 - acc: 0.9600 - val_loss: 0.2153 - val_acc: 0.9256\n","Epoch 40/50\n","48000/48000 [==============================] - 46s 950us/step - loss: 0.1038 - acc: 0.9611 - val_loss: 0.2171 - val_acc: 0.9278\n","Epoch 41/50\n","48000/48000 [==============================] - 45s 946us/step - loss: 0.0995 - acc: 0.9622 - val_loss: 0.2154 - val_acc: 0.9257\n","Epoch 42/50\n","48000/48000 [==============================] - 47s 972us/step - loss: 0.0943 - acc: 0.9650 - val_loss: 0.2155 - val_acc: 0.9273\n","Epoch 43/50\n","48000/48000 [==============================] - 44s 926us/step - loss: 0.0916 - acc: 0.9658 - val_loss: 0.2155 - val_acc: 0.9298\n","Epoch 44/50\n","48000/48000 [==============================] - 44s 919us/step - loss: 0.0905 - acc: 0.9660 - val_loss: 0.2342 - val_acc: 0.9240\n","Epoch 45/50\n","48000/48000 [==============================] - 44s 922us/step - loss: 0.0879 - acc: 0.9676 - val_loss: 0.2252 - val_acc: 0.9272\n","Epoch 46/50\n","48000/48000 [==============================] - 45s 933us/step - loss: 0.0864 - acc: 0.9677 - val_loss: 0.2200 - val_acc: 0.9290\n","Epoch 47/50\n","48000/48000 [==============================] - 45s 943us/step - loss: 0.0804 - acc: 0.9700 - val_loss: 0.2242 - val_acc: 0.9272\n","Epoch 48/50\n","48000/48000 [==============================] - 46s 950us/step - loss: 0.0809 - acc: 0.9688 - val_loss: 0.2333 - val_acc: 0.9250\n","Epoch 49/50\n","48000/48000 [==============================] - 45s 928us/step - loss: 0.0819 - acc: 0.9695 - val_loss: 0.2582 - val_acc: 0.9232\n","Epoch 50/50\n","48000/48000 [==============================] - 45s 942us/step - loss: 0.0813 - acc: 0.9694 - val_loss: 0.2331 - val_acc: 0.9295\n","Train on 48000 samples, validate on 12000 samples\n","Epoch 1/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.7536 - acc: 0.7276 - val_loss: 0.4254 - val_acc: 0.8515\n","Epoch 2/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.4554 - acc: 0.8364 - val_loss: 0.3535 - val_acc: 0.8730\n","Epoch 3/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.3857 - acc: 0.8601 - val_loss: 0.3217 - val_acc: 0.8808\n","Epoch 4/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.3492 - acc: 0.8736 - val_loss: 0.2945 - val_acc: 0.8890\n","Epoch 5/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.3197 - acc: 0.8836 - val_loss: 0.2692 - val_acc: 0.8993\n","Epoch 6/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.3006 - acc: 0.8910 - val_loss: 0.2593 - val_acc: 0.9017\n","Epoch 7/50\n","48000/48000 [==============================] - 99s 2ms/step - loss: 0.2832 - acc: 0.8952 - val_loss: 0.2492 - val_acc: 0.9065\n","Epoch 8/50\n","48000/48000 [==============================] - 100s 2ms/step - loss: 0.2696 - acc: 0.9006 - val_loss: 0.2434 - val_acc: 0.9097\n","Epoch 9/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.2569 - acc: 0.9052 - val_loss: 0.2390 - val_acc: 0.9114\n","Epoch 10/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.2464 - acc: 0.9095 - val_loss: 0.2356 - val_acc: 0.9124\n","Epoch 11/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.2363 - acc: 0.9125 - val_loss: 0.2268 - val_acc: 0.9157\n","Epoch 12/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.2284 - acc: 0.9147 - val_loss: 0.2223 - val_acc: 0.9153\n","Epoch 13/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.2219 - acc: 0.9177 - val_loss: 0.2244 - val_acc: 0.9154\n","Epoch 14/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.2116 - acc: 0.9205 - val_loss: 0.2195 - val_acc: 0.9184\n","Epoch 15/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.2061 - acc: 0.9216 - val_loss: 0.2210 - val_acc: 0.9202\n","Epoch 16/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.2013 - acc: 0.9252 - val_loss: 0.2215 - val_acc: 0.9187\n","Epoch 17/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.1970 - acc: 0.9257 - val_loss: 0.2192 - val_acc: 0.9189\n","Epoch 18/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.1864 - acc: 0.9299 - val_loss: 0.2118 - val_acc: 0.9227\n","Epoch 19/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.1839 - acc: 0.9302 - val_loss: 0.2085 - val_acc: 0.9227\n","Epoch 20/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.1754 - acc: 0.9341 - val_loss: 0.2138 - val_acc: 0.9210\n","Epoch 21/50\n","48000/48000 [==============================] - 104s 2ms/step - loss: 0.1746 - acc: 0.9337 - val_loss: 0.2093 - val_acc: 0.9251\n","Epoch 22/50\n","48000/48000 [==============================] - 102s 2ms/step - loss: 0.1667 - acc: 0.9363 - val_loss: 0.2194 - val_acc: 0.9210\n","Epoch 23/50\n","48000/48000 [==============================] - 100s 2ms/step - loss: 0.1665 - acc: 0.9366 - val_loss: 0.2093 - val_acc: 0.9233\n","Epoch 24/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1634 - acc: 0.9382 - val_loss: 0.2100 - val_acc: 0.9251\n","Epoch 25/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1580 - acc: 0.9394 - val_loss: 0.2149 - val_acc: 0.9222\n","Epoch 26/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.1535 - acc: 0.9414 - val_loss: 0.2126 - val_acc: 0.9255\n","Epoch 27/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.1482 - acc: 0.9430 - val_loss: 0.2098 - val_acc: 0.9252\n","Epoch 28/50\n","48000/48000 [==============================] - 100s 2ms/step - loss: 0.1467 - acc: 0.9450 - val_loss: 0.2170 - val_acc: 0.9247\n","Epoch 29/50\n","48000/48000 [==============================] - 100s 2ms/step - loss: 0.1431 - acc: 0.9460 - val_loss: 0.2142 - val_acc: 0.9272\n","Epoch 30/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.1400 - acc: 0.9458 - val_loss: 0.2127 - val_acc: 0.9261\n","Epoch 31/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.1343 - acc: 0.9485 - val_loss: 0.2182 - val_acc: 0.9265\n","Epoch 32/50\n","48000/48000 [==============================] - 100s 2ms/step - loss: 0.1351 - acc: 0.9491 - val_loss: 0.2178 - val_acc: 0.9258\n","Epoch 33/50\n","48000/48000 [==============================] - 105s 2ms/step - loss: 0.1311 - acc: 0.9496 - val_loss: 0.2097 - val_acc: 0.9271\n","Epoch 34/50\n","48000/48000 [==============================] - 104s 2ms/step - loss: 0.1292 - acc: 0.9506 - val_loss: 0.2176 - val_acc: 0.9255\n","Epoch 35/50\n","48000/48000 [==============================] - 103s 2ms/step - loss: 0.1255 - acc: 0.9524 - val_loss: 0.2128 - val_acc: 0.9282\n","Epoch 36/50\n","48000/48000 [==============================] - 102s 2ms/step - loss: 0.1266 - acc: 0.9508 - val_loss: 0.2179 - val_acc: 0.9274\n","Epoch 37/50\n","48000/48000 [==============================] - 102s 2ms/step - loss: 0.1206 - acc: 0.9524 - val_loss: 0.2161 - val_acc: 0.9282\n","Epoch 38/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1210 - acc: 0.9534 - val_loss: 0.2175 - val_acc: 0.9287\n","Epoch 39/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1166 - acc: 0.9539 - val_loss: 0.2215 - val_acc: 0.9281\n","Epoch 40/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.1175 - acc: 0.9546 - val_loss: 0.2215 - val_acc: 0.9276\n","Epoch 41/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1116 - acc: 0.9570 - val_loss: 0.2191 - val_acc: 0.9305\n","Epoch 42/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.1110 - acc: 0.9570 - val_loss: 0.2305 - val_acc: 0.9273\n","Epoch 43/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.1092 - acc: 0.9574 - val_loss: 0.2333 - val_acc: 0.9261\n","Epoch 44/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1076 - acc: 0.9590 - val_loss: 0.2382 - val_acc: 0.9262\n","Epoch 45/50\n","48000/48000 [==============================] - 98s 2ms/step - loss: 0.1070 - acc: 0.9589 - val_loss: 0.2265 - val_acc: 0.9287\n","Epoch 46/50\n","48000/48000 [==============================] - 96s 2ms/step - loss: 0.1030 - acc: 0.9591 - val_loss: 0.2341 - val_acc: 0.9276\n","Epoch 47/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.1031 - acc: 0.9600 - val_loss: 0.2392 - val_acc: 0.9281\n","Epoch 48/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.1027 - acc: 0.9607 - val_loss: 0.2257 - val_acc: 0.9278\n","Epoch 49/50\n","48000/48000 [==============================] - 95s 2ms/step - loss: 0.1024 - acc: 0.9607 - val_loss: 0.2313 - val_acc: 0.9281\n","Epoch 50/50\n","48000/48000 [==============================] - 97s 2ms/step - loss: 0.0989 - acc: 0.9622 - val_loss: 0.2317 - val_acc: 0.9282\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iQ6I1JLwQ6Uu","colab_type":"text"},"source":["## **TESTING AND RESULTS**"]},{"cell_type":"code","metadata":{"id":"JdZSa-V7dMK3","colab_type":"code","outputId":"34a7d8e2-6562-4784-c0f1-89a73cf52c75","executionInfo":{"status":"ok","timestamp":1572097475975,"user_tz":-420,"elapsed":10759,"user":{"displayName":"Satria Wiro Agung","photoUrl":"","userId":"00696212505222063717"}},"colab":{"base_uri":"https://localhost:8080/","height":630}},"source":["count = 0;\n","for model in cnn_models:\n","  count = count + 1\n","  print(\"=============================================================\")\n","  print(\"|            MODEL \",count,\" (\",count,\" CONVOLUTIONAL LAYER)            |\")\n","  print(\"=============================================================\")\n","  score,acc = model.evaluate(testDatas,testLabels)\n","  print(\"-------------------------------------------------------------\")\n","  print(\"Test Score    : \" , score)\n","  print(\"Test Accuracy : \" , acc)\n","  print(\"-------------------------------------------------------------\")\n","  print(\"=============================================================\")\n","  print(\"\\n\")\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["=============================================================\n","|            MODEL  1  ( 1  CONVOLUTIONAL LAYER)            |\n","=============================================================\n","10000/10000 [==============================] - 2s 181us/step\n","-------------------------------------------------------------\n","Test Score    :  0.26603957515954973\n","Test Accuracy :  0.912\n","-------------------------------------------------------------\n","=============================================================\n","\n","\n","=============================================================\n","|            MODEL  2  ( 2  CONVOLUTIONAL LAYER)            |\n","=============================================================\n","10000/10000 [==============================] - 3s 285us/step\n","-------------------------------------------------------------\n","Test Score    :  0.24966826938390732\n","Test Accuracy :  0.9253\n","-------------------------------------------------------------\n","=============================================================\n","\n","\n","=============================================================\n","|            MODEL  3  ( 3  CONVOLUTIONAL LAYER)            |\n","=============================================================\n","10000/10000 [==============================] - 6s 553us/step\n","-------------------------------------------------------------\n","Test Score    :  0.26061647060588\n","Test Accuracy :  0.926\n","-------------------------------------------------------------\n","=============================================================\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vi50FTstRJAt","colab_type":"text"},"source":["Dari diatas diketahui model dengan akurasi tertinggi adalah Model 3 (3 Convolutional Layer).\n","Urutan model berdasarkan akurasi : \n","1. Model 3 (0.926)\n","2. Model 2 (0.9253)\n","3. Model 1 (0.912)\n","\n","Test Score adalah hasil evaluasi dari loss function. Semakin kecil loss semakin kecil prediction errornya. Jika berdasarkan test score maka yang prediksinya paling sedikit errornya adalah model ke 2.\n","\n","Dari hasil diatas dapat disimpulkan : \n","\n","- Model 1 dengan 1 convolutional layer memiliki akurasi dan loss yang lebih buruk dari pada model 2 dan model 3.\n","- Model 3 dengan 3 convolutional layer memilki akurasi paling bagus daripada model 1 dan model 2. Tetapi memiliki loss yang lebih tinggi dari pada model 2.\n","- Model 2 dengan 2 convolutional layer memiliki loss paling rendah daripada yang lain. Dari segi akurasi, model 2 hanya berbeda 0.001 (0.1 persen) dengan model 1 yang memiliki akurasi tertinggi.\n","- Secara keseluruhan, Model 2 memiliki keseimbangan/rata-rata loss dan accuracy paling bagus. Karena akurasi model 2 hanya beda sekitar 0.1 persen dengan model 1 (model dengan akurasi paling tinggi) dan model 2 mempunyai loss (kesalahan prediksi) yang paling rendah."]}]}